{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "  quality = 0.5\n",
    "  alpha = 1\n",
    "  beta = 1\n",
    "  good = 0\n",
    "  \n",
    "\n",
    "  def __init__(self, quality):\n",
    "    self.quality = quality\n",
    "  \n",
    "\n",
    "  def sample_distribution(self):\n",
    "    return np.random.beta(self.alpha, self.beta)\n",
    "  \n",
    "  \n",
    "  def get_element(self):\n",
    "    good = np.random.rand() < self.quality\n",
    "    self.alpha = self.alpha + int(good)\n",
    "    self.beta = self.beta + 1 - int(good)\n",
    "    return good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwapLemon:\n",
    "  batches = []\n",
    "  systems = 0\n",
    "  good = 0\n",
    "  current_batch = 0\n",
    "  name = 'SwapLemon'\n",
    "\n",
    "  def set_batches(self, qualities, _):\n",
    "    self.batches = [Batch(quality) for quality in qualities]\n",
    "    self.systems = 0\n",
    "    self.good = 0\n",
    "  \n",
    "  def get_element(self):\n",
    "    if self.batches[self.current_batch].get_element():\n",
    "        self.systems += 1\n",
    "        self.good += 1\n",
    "    else:\n",
    "        self.systems += 1\n",
    "        if self.current_batch < len(batches)-1:\n",
    "            self.current_batch += 1\n",
    "        else:\n",
    "            self.current_batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nBayes:\n",
    "  batches = []\n",
    "  systems = 0\n",
    "  good = 0\n",
    "  current_batch = 0\n",
    "  epoch = 0\n",
    "  training = 0\n",
    "  in_training = True\n",
    "  order =[]\n",
    "  name = 'nBayes'\n",
    "\n",
    "\n",
    "  def set_batches(self, qualities, training):\n",
    "    self.batches = [Batch(quality) for quality in qualities]\n",
    "    self.systems = 0\n",
    "    self.good = 0\n",
    "    self.training = len(batches)*training\n",
    "    self.order = []\n",
    "\n",
    "\n",
    "  def get_element(self):\n",
    "    if self.in_training:  \n",
    "        self.epoch +=1\n",
    "        self.systems += 1\n",
    "        if self.batches[self.current_batch].get_element():\n",
    "            self.good += 1\n",
    "            self.batches[self.current_batch].good += 1\n",
    "            \n",
    "        if self.current_batch < len(batches)-1:\n",
    "            self.current_batch += 1\n",
    "\n",
    "        else:\n",
    "            self.current_batch = 0\n",
    "\n",
    "        if self.epoch >= self.training:\n",
    "            self.in_training = False\n",
    "            self.epoch = 0\n",
    "            order = []\n",
    "            scores = [x.good for x in self.batches] \n",
    "            for i in range(len(scores)):\n",
    "                for _ in range(len(batches)-i):\n",
    "                    self.order.append(np.argmax(scores))\n",
    "                    \n",
    "                scores[np.argmax(scores)] = -1\n",
    "\n",
    "    else:\n",
    "        if self.epoch > len(self.order)-1:\n",
    "            self.epoch = 0\n",
    "        \n",
    "        self.systems += 1\n",
    "        if self.batches[self.order[self.epoch]].get_element():\n",
    "            self.good += 1\n",
    "        \n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sBayes:\n",
    "    batches = []\n",
    "    systems = 0\n",
    "    good = 0\n",
    "    current_batch = 0\n",
    "    epoch = 0\n",
    "    training = 0\n",
    "    in_training = True\n",
    "    order =[]\n",
    "    name = 'sBayes'\n",
    "\n",
    "\n",
    "    def set_batches(self, qualities, training):\n",
    "        self.batches = [Batch(quality) for quality in qualities]\n",
    "        self.systems = 0\n",
    "        self.good = 0\n",
    "        self.training = len(batches)*training\n",
    "        self.order = []\n",
    "\n",
    "\n",
    "    def get_element(self):\n",
    "        if self.in_training:  \n",
    "            self.epoch +=1\n",
    "            self.systems += 1\n",
    "            if self.batches[self.current_batch].get_element():\n",
    "                self.good += 1\n",
    "                self.batches[self.current_batch].good += 1\n",
    "                \n",
    "            if self.current_batch < len(batches)-1:\n",
    "                self.current_batch += 1\n",
    "\n",
    "            else:\n",
    "                self.current_batch = 0\n",
    "    \n",
    "            if self.epoch >= self.training:\n",
    "                self.in_training = False\n",
    "                self.epoch = 0\n",
    "                scores = [x.good for x in self.batches]\n",
    "                scores2 = scores.copy()\n",
    "                last_count = 1\n",
    "                for i in range(len(scores)):\n",
    "                    if i == 0:\n",
    "                        self.order.append(np.argmin(scores))\n",
    "                        scores[np.argmin(scores)] = 1_000_000\n",
    "                        \n",
    "                    else:\n",
    "                        si_minus_1 = scores2[self.order[-1]]\n",
    "                        si = scores2[i]\n",
    "                        if si_minus_1 == 0:\n",
    "                            si_minus_1 = 1\n",
    "\n",
    "                        last_count *= round(si/si_minus_1)\n",
    "                        for a in range(last_count):\n",
    "                            self.order.append(np.argmin(scores))\n",
    "\n",
    "                        scores[np.argmin(scores)] = 1_000_000\n",
    "                self.order.reverse()\n",
    "\n",
    "        else:\n",
    "            if self.epoch > len(self.order)-1:\n",
    "                self.epoch = 0\n",
    "            \n",
    "            self.systems += 1\n",
    "            if self.batches[self.order[self.epoch]].get_element():\n",
    "                self.good += 1\n",
    "            \n",
    "            self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBayes:\n",
    "    batches = []\n",
    "    systems = 0\n",
    "    good = 0\n",
    "    current_batch = 0\n",
    "    epoch = 0\n",
    "    training = 0\n",
    "    in_training = True\n",
    "    order = []\n",
    "    name = 'MyBayes'\n",
    "    \n",
    "    \n",
    "    def set_batches(self, qualities, training):\n",
    "        self.batches = [Batch(quality) for quality in qualities]\n",
    "        self.systems = 0\n",
    "        self.good = 0\n",
    "        self.training = len(batches)*training\n",
    "        self.order = []\n",
    "    \n",
    "\n",
    "    def get_element(self):\n",
    "        if self.in_training:  \n",
    "            self.epoch +=1\n",
    "            self.systems += 1\n",
    "            if self.batches[self.current_batch].get_element():\n",
    "                self.systems += 1\n",
    "                self.good += 1\n",
    "            else:\n",
    "                self.systems += 1\n",
    "            if self.current_batch < len(batches)-1:\n",
    "                self.current_batch += 1\n",
    "            else:\n",
    "                self.current_batch = 0\n",
    "\n",
    "            if self.epoch >= self.training:\n",
    "                self.in_training = False\n",
    "                self.epoch = 0\n",
    "                scores = [x.good for x in self.batches] \n",
    "                for _ in range(len(scores)):\n",
    "                    self.order.append(np.argmax(scores))\n",
    "                self.current_batch = self.order[0]\n",
    "    \n",
    "        else:\n",
    "          self.systems+=1\n",
    "          if self.batches[self.current_batch].get_element():\n",
    "            self.good += 1\n",
    "    \n",
    "          else:\n",
    "            self.current_batch = random.choice(self.order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average succes ratio for SwapLemon: 80.26%\n",
      "Average succes ratio for nBayes: 70.94%\n",
      "Average succes ratio for sBayes: 59.09%\n",
      "Average succes ratio for MyBayes: 89.97%\n"
     ]
    }
   ],
   "source": [
    "tries = 100 \n",
    "epoch = 10000\n",
    "learning = 50\n",
    "batches = [0.95, 0.85, 0.75, 0.65, 0.55, 0.45, 0.35, 0.25]\n",
    "bayes_dict = {'SwapLemon': 0,'nBayes': 0, 'sBayes': 0, 'MyBayes': 0}\n",
    "for _ in range(tries):\n",
    "    swap_lemon = SwapLemon()\n",
    "    n_bayes = nBayes()\n",
    "    s_bayes = sBayes()\n",
    "    my_bayes = MyBayes()\n",
    "    bayes_lst = [swap_lemon, n_bayes, s_bayes, my_bayes]\n",
    "    for bayes in bayes_lst:\n",
    "        bayes.set_batches(batches, learning)\n",
    "        for i in range(epoch):\n",
    "            bayes.get_element()\n",
    "        bayes_dict[bayes.name] += bayes.good/bayes.systems\n",
    "\n",
    "\n",
    "for key in bayes_dict.keys():\n",
    "    print(f'Average succes ratio for {key}: {bayes_dict[key]/tries:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average succes ratio for SwapLemon: 78.67%\n",
      "Average succes ratio for nBayes: 71.33%\n",
      "Average succes ratio for sBayes: 69.67%\n",
      "Average succes ratio for MyBayes: 84.57%\n"
     ]
    }
   ],
   "source": [
    "tries = 3\n",
    "epoch = 100\n",
    "learning = 1\n",
    "batches = [0.95, 0.85, 0.75, 0.65, 0.55, 0.45, 0.35, 0.25]\n",
    "bayes_dict = {'SwapLemon': 0,'nBayes': 0, 'sBayes': 0, 'MyBayes': 0}\n",
    "for _ in range(tries):\n",
    "    swap_lemon = SwapLemon()\n",
    "    n_bayes = nBayes()\n",
    "    s_bayes = sBayes()\n",
    "    my_bayes = MyBayes()\n",
    "    bayes_lst = [swap_lemon, n_bayes, s_bayes, my_bayes]\n",
    "    for bayes in bayes_lst:\n",
    "        bayes.set_batches(batches, learning)\n",
    "        for i in range(epoch):\n",
    "            bayes.get_element()\n",
    "        bayes_dict[bayes.name] += bayes.good/bayes.systems\n",
    "\n",
    "\n",
    "for key in bayes_dict.keys():\n",
    "    print(f'Average succes ratio for {key}: {bayes_dict[key]/tries:.2%}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moja strategia opiera się w dużej mierze na strategii SkipLemon dodałem to niej metode uczenia tak jak w przypadku nBayesa i sBayesa. Gdy producent nie jest dobry zostaje wybrany losowy i proces uczenie jest kontynuowany. Moja klasa uczy sie zaskakująco szybko w 3 próbach i skaląuczenie ustawioną na 1. Prawdopodobnie zawdzięcza to temu ze szybko ten najlepszy jest wybierany a pozostałe skipowane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in bayes_dict.keys():\n",
    "    bayes_dict[key] = bayes_dict[key]/tries\n",
    "\n",
    "plt.bar(*zip(*bayes_dict.items()))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e04553695969d4d47faf5f6cb6680defa9132066165e6d56f61a0a2813d22dbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
